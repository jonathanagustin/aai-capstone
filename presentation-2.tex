\documentclass[aspectratio=169]{beamer}

% Modern theme & fonts with T1 encoding
\usetheme{metropolis}
\usefonttheme{professionalfonts}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{bookmark}

% Metropolis adjustments
\metroset{progressbar=none}
\setbeamertemplate{footline}{}

% Colors and frame title formatting
\setbeamercolor{normal text}{fg=black,bg=white}
\setbeamercolor{background canvas}{bg=white}
\setbeamercolor{frametitle}{fg=black,bg=white}

% Center frame titles
\makeatletter
\setbeamertemplate{frametitle}{
  \nointerlineskip%
  \begin{beamercolorbox}[wd=\paperwidth, sep=0.3cm, center]{frametitle}%
    \usebeamerfont{frametitle}\insertframetitle\par%
    \if\insertframesubtitle\relax%
    \else%
      \vspace{0.5em}%
      {\usebeamerfont{framesubtitle}\insertframesubtitle\par}%
    \fi%
  \end{beamercolorbox}%
}
\makeatother

% Packages
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    bookmarksnumbered=true
}
\usepackage{etoolbox}
\usepackage{media9}
\usepackage{minted}
\usemintedstyle{friendly}
\usepackage{menukeys}

\title{Data Preparation \& Ethical Data Handling}
\subtitle{AI Masters Capstone Project - Presentation 2}
\author{Jonathan Agustin}
\date{November 2024}

\begin{document}

%------------------------------------------------------------
% Title Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Welcome back. In our first presentation, we explored the bigger picture—building automated ML pipelines with ethical foundations. Now, let’s go deeper into the heart of any ML workflow: the data.
%
% Data is the raw material that fuels machine learning. But it’s not just about quantity or even quality; it’s about handling data ethically, ensuring fairness, respecting privacy, and preventing biases from creeping in at the earliest stages.
%
% In this presentation, we’ll tackle data preparation from a holistic perspective. We’ll see how to clean and transform data automatically, enforce data protection laws, guard against harmful biases, and maintain the trust of the people our models serve.
%
% Let’s dive into the world of ethical data handling.
%%% VOICEOVER OFF
\maketitle

%------------------------------------------------------------
% Overview Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Here’s our roadmap for this presentation:
%
% 1. We’ll start by understanding why ethical data handling matters so much—not just to avoid bad press, but to genuinely serve users fairly.
% 2. Then we’ll discuss automated data preprocessing techniques—how to detect missing values, fix inconsistencies, and handle diverse data formats.
% 3. We’ll explore how to ensure data quality and reliability through validation and error detection.
% 4. We’ll integrate ethics into each step—privacy protection, GDPR compliance, and safeguarding sensitive information.
% 5. Finally, we’ll address bias detection and mitigation, ensuring we don’t entrench unfairness in our models.
%%% VOICEOVER OFF
\begin{frame}{What We’ll Cover Today}
\begin{itemize}
\item Why ethical data handling is essential, not optional
\item Automated preprocessing: cleaning, transforming, validating data
\item Ensuring data quality and reliability with systematic checks
\item Respecting privacy, complying with regulations (e.g., GDPR)
\item Detecting and mitigating bias to build fair, trustworthy models
\end{itemize}

\vspace{0.8em}
\emph{By the end, you’ll have concrete practices to ensure data is a strength, not a liability.}
\end{frame}

%------------------------------------------------------------
% Importance of Ethical Data Handling
%------------------------------------------------------------
%%% VOICEOVER ON
% Data isn’t just numbers and text—it represents people, their behaviors, their lives. Handling it ethically isn’t merely a compliance task; it’s about respect and responsibility.
%
% When companies mishandle data—leaking sensitive information, fueling biased decisions—they erode public trust and harm real individuals.
%
% Ethical data handling builds credibility, fosters user trust, and reduces legal and reputational risks. More importantly, it ensures our AI solutions uplift rather than oppress.
%
% Let’s commit to putting human values at the center of our data practices.
%%% VOICEOVER OFF
\begin{frame}{Why Ethical Data Handling Matters}
\begin{itemize}
\item Data represents real people, not just abstract entries
\item Ethical handling protects privacy, dignity, and fairness
\item Avoiding biases and breaches maintains trust and credibility
\end{itemize}

\vspace{0.8em}
\emph{Ethical data stewardship is the foundation of user trust and sustainable ML solutions.}

% [OPTIONAL IMAGE HERE: Icon of a lock or shield over a database]
\end{frame}

%------------------------------------------------------------
% Automated Data Preprocessing Intro
%------------------------------------------------------------
%%% VOICEOVER ON
% Data rarely arrives in a perfect form. It might have missing values, inconsistent formats, outliers, or redundancies. Doing this cleaning and transformation by hand is error-prone and time-consuming.
%
% Automated preprocessing scripts streamline these tasks: detecting missing values, handling outliers gracefully, merging datasets, and ensuring consistent formats.
%
% Automation frees data scientists to focus on insights rather than grunt work, and it creates repeatable, transparent processes that enhance quality and fairness.
%%% VOICEOVER OFF
\begin{frame}{Automated Data Preprocessing}
\begin{itemize}
\item Handle missing values, outliers, and inconsistencies automatically
\item Uniformly transform data, standardizing features and formats
\item Reduce human error and foster reproducible, transparent data workflows
\end{itemize}

\vspace{0.8em}
\emph{Automation shifts focus from manual cleanup to building reliable, ethical pipelines.}

% [OPTIONAL IMAGE HERE: Data cleaning icons or code snippet representation]
\end{frame}

%------------------------------------------------------------
% Techniques for Data Cleaning and Transformation
%------------------------------------------------------------
%%% VOICEOVER ON
% How do we implement automated preprocessing?
%
% For example:
% - Use scripts or frameworks to detect missing values and choose appropriate strategies (imputation, removal, or special markers).
% - Identify outliers using statistical methods or domain knowledge, deciding whether to cap them, transform them, or exclude them.
% - Standardize units, convert categorical variables, and handle text fields uniformly.
%
% By encoding these rules in code, we ensure consistency, reduce manual intervention, and maintain a clear audit trail.
%%% VOICEOVER OFF
\begin{frame}{Practical Preprocessing Techniques}
\begin{itemize}
\item Missing data: Impute (mean, median), flag or remove strategically
\item Outliers: Apply robust statistical checks or domain-specific thresholds
\item Feature standardization: Convert formats, ensure consistent units, encode categories
\end{itemize}

\vspace{0.8em}
\emph{Well-defined preprocessing rules build confidence and clarity into data pipelines.}

% [OPTIONAL IMAGE HERE: Before/After data table illustration]
\end{frame}

%------------------------------------------------------------
% Data Validation and Quality Assurance
%------------------------------------------------------------
%%% VOICEOVER ON
% Even after cleaning, we must validate data quality. Automated validation scripts can detect anomalies—like unexpected null spikes or mismatched schemas—early in the pipeline.
%
% Quality assurance tools catch errors before they poison training sets. They can warn if a critical feature is missing, or if data distributions shift suspiciously over time.
%
% Ensuring data integrity means our models stand on a solid foundation, not a shaky pile of questionable inputs.
%%% VOICEOVER OFF
\begin{frame}{Data Quality Assurance}
\begin{itemize}
\item Implement validation checks: schema conformity, range checks, uniqueness tests
\item Detect anomalies early: unusual patterns, distribution shifts, missing critical features
\item Maintain logs and reports to track data quality trends over time
\end{itemize}

\vspace{0.8em}
\emph{Robust validation turns raw data into a trusted resource for responsible AI.}

% [OPTIONAL IMAGE HERE: Magnifying glass over dataset icon]
\end{frame}

%------------------------------------------------------------
% Ethical Data Management: Privacy & Regulations
%------------------------------------------------------------
%%% VOICEOVER ON
% Ethics extend beyond fairness—privacy and regulatory compliance are non-negotiable.
%
% Consider GDPR: it mandates data protection, user consent, and the right to be forgotten. We must incorporate anonymization, pseudonymization, and encryption where needed.
%
% Respecting sensitive data—like health or financial info—means implementing strict access controls. Automated pipelines can enforce these rules, ensuring no unauthorized exposure.
%
% By embedding privacy safeguards, we honor the trust users place in our systems.
%%% VOICEOVER OFF
\begin{frame}{Privacy Protection and Compliance}
\begin{itemize}
\item Implement anonymization or pseudonymization for sensitive identifiers
\item Follow GDPR and other regulations: user consent, data minimization, right to erasure
\item Restrict access, log data handling actions, and maintain thorough documentation
\end{itemize}

\vspace{0.8em}
\emph{Privacy isn’t just legal compliance—it’s respecting human rights and autonomy.}

% [OPTIONAL IMAGE HERE: A padlock over a database or shield icon]
\end{frame}

%------------------------------------------------------------
% Ethical Data Management: Bias Detection
%------------------------------------------------------------
%%% VOICEOVER ON
% Even clean, validated, and private data can still harbor biases. Historical imbalances or sampling errors may skew our training sets.
%
% Bias detection methods—like comparing outcomes across demographic groups—help us spot if certain populations are underrepresented or inaccurately represented.
%
% Automated reports can flag suspicious patterns: Are women systematically assigned lower credit scores after preprocessing? Are certain ethnic groups missing from the dataset?
%
% Identifying bias early means we can correct it before training, ensuring we don’t encode societal injustices into our models.
%%% VOICEOVER OFF
\begin{frame}{Detecting and Mitigating Bias}
\begin{itemize}
\item Use fairness metrics: parity checks across demographic segments
\item Monitor representation: ensure no group is disproportionately excluded
\item Adjust preprocessing steps or sampling strategies to rebalance the data
\end{itemize}

\vspace{0.8em}
\emph{Catching bias in the data stage prevents deploying models that perpetuate discrimination.}

% [OPTIONAL IMAGE HERE: Balanced scale comparing two subsets of data]
\end{frame}

%------------------------------------------------------------
% Putting It All Together
%------------------------------------------------------------
%%% VOICEOVER ON
% We’ve explored data handling from multiple angles—automation, validation, privacy, and bias mitigation. Each of these threads weaves together into a holistic approach.
%
% A well-designed pipeline ensures data flows from raw sources into ethically prepared training sets. It respects regulations, maintains quality, protects privacy, and guards against bias.
%
% In the next steps, we’ll integrate these principles into the larger ML pipeline. By doing so, we ensure that every model we build rests on a solid, fair, and responsible data foundation.
%%% VOICEOVER OFF
\begin{frame}{A Holistic Data Strategy}
\begin{itemize}
\item Combine automation, validation, privacy measures, and bias checks into one pipeline
\item Document every step for transparency and accountability
\item Set the stage for fair, impactful ML models built on trustworthy data
\end{itemize}

\vspace{0.8em}
\emph{A robust, ethical data pipeline empowers us to build AI that genuinely benefits everyone.}

% [OPTIONAL IMAGE HERE: Pipeline diagram showing data input and checks at each stage]
\end{frame}

%------------------------------------------------------------
% Conclusion & Next Steps
%------------------------------------------------------------
%%% VOICEOVER ON
% We’ve delved deep into data preparation and ethical handling, setting the stage for the rest of our journey.
%
% Next, we’ll move into automating model training and ensuring that ethical principles carry over into model development itself. We’ll see how reproducibility, versioning, and fairness metrics continue to guide our workflow.
%
% With a solid, ethical data foundation in place, we’re one step closer to delivering AI solutions that are efficient, fair, and trusted by all.
%%% VOICEOVER OFF
\begin{frame}{Next Steps}
\begin{itemize}
\item Next Presentation: Automating Model Training \& Ensuring Fairness
\item Building on our ethical data pipeline to create responsible models
\end{itemize}

\vspace{0.8em}
\emph{From well-prepared data to ethically trained models—the journey continues.}
\end{frame}

\end{document}
