\documentclass[aspectratio=169]{beamer}

% Modern theme & fonts with T1 encoding
\usetheme{metropolis}
\usefonttheme{professionalfonts}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{bookmark}

% Metropolis adjustments
\metroset{progressbar=none}
\setbeamertemplate{footline}{}

% Colors and frame title formatting
\setbeamercolor{normal text}{fg=black,bg=white}
\setbeamercolor{background canvas}{bg=white}
\setbeamercolor{frametitle}{fg=black,bg=white}

% Center frame titles
\makeatletter
\setbeamertemplate{frametitle}{
  \nointerlineskip%
  \begin{beamercolorbox}[wd=\paperwidth, sep=0.3cm, center]{frametitle}%
    \usebeamerfont{frametitle}\insertframetitle\par%
    \if\insertframesubtitle\relax%
    \else%
      \vspace{0.5em}%
      {\usebeamerfont{framesubtitle}\insertframesubtitle\par}%
    \fi%
  \end{beamercolorbox}%
}
\makeatother

% Packages
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    bookmarksnumbered=true
}
\usepackage{etoolbox}
\usepackage{media9}
\usepackage{minted}
\usemintedstyle{friendly}
\usepackage{menukeys}

\title{Data Preparation \& Ethical Data Handling}
\subtitle{AI Masters Capstone Project - Presentation 2}
\author{Jonathan Agustin}
\date{November 2024}

\begin{document}

%------------------------------------------------------------
% Title Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Welcome back to our deep dive into building ethical and automated ML pipelines.
% In our first presentation, we explored the overarching framework of automation and ethics in ML.
% Now, we move to the heart of an ML workflow: the data itself.
%
% Data is the raw fuel that powers machine learning models. However, raw data is often messy, incomplete, and potentially biased. Our job is to transform this raw material into something that’s clean, consistent, private, and as fair as possible.
%
% In this session, we’ll not only discuss why ethical data handling is crucial; we’ll walk through practical preprocessing techniques, code examples, and methods for privacy protection and bias mitigation. Our goal is to make this all very tangible—something you can take back to your codebase and implement tomorrow.
%
% Let’s begin by reaffirming the importance of approaching data with an ethical mindset.
%%% VOICEOVER OFF
\maketitle

%------------------------------------------------------------
% Overview Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Here’s what we’ll cover today:
% 1. Why ethical data handling is essential and what it entails beyond just compliance.
% 2. Automated preprocessing techniques—going beyond theoretical steps to show actual code for handling missing data, outliers, and transforming features.
% 3. Data validation and quality checks—seeing how to integrate these into automated scripts so we catch issues before model training.
% 4. Privacy considerations and compliance with regulations like GDPR, including strategies like pseudonymization and encryption.
% 5. Bias detection and mitigation, with hands-on examples of how to measure and reduce unwanted biases in your datasets.
%
% By the end, you’ll have practical tools and a code-centric roadmap for building a trustworthy, fair, and private ML data pipeline.
%%% VOICEOVER OFF
\begin{frame}{What We’ll Cover Today}
\begin{itemize}
\item Why ethical data handling matters: trust, fairness, reputation
\item Practical, automated preprocessing: from cleaning to transformation
\item Ensuring data quality: validation scripts and continuous checks
\item Privacy and compliance: embedding GDPR and data protection into your pipeline
\item Identifying and mitigating bias: concrete techniques and tools
\end{itemize}

\vspace{0.8em}
\emph{Our focus: Move from theory to practice, ensuring data integrity, privacy, and fairness.}
\end{frame}

%------------------------------------------------------------
% Importance of Ethical Data Handling
%------------------------------------------------------------
%%% VOICEOVER ON
% Ethical data handling goes beyond avoiding fines or bad press. It’s about respecting the people represented in our datasets.
%
% Every row could be someone’s health record, financial history, or career opportunity. By ethically handling data, we:
% - Protect privacy and reduce potential harm if data is leaked or misused.
% - Retain public trust, making people more willing to share data and use our products.
% - Create models that are fair and just, improving societal outcomes rather than reinforcing biases.
%
% Treating data ethically is not just a moral imperative; it’s essential for building long-term trust and sustainable AI products.
%%% VOICEOVER OFF
\begin{frame}{Why Ethical Data Handling Matters}
\begin{itemize}
\item Data = real individuals’ personal details, behaviors, and rights
\item Trust and credibility: A must for sustainable product adoption
\item Reduces legal risks and reputational damage from misuse or bias
\end{itemize}

\emph{Ethical data stewardship is the moral and practical cornerstone of responsible AI.}
\end{frame}

%------------------------------------------------------------
% Automated Data Preprocessing Intro
%------------------------------------------------------------
%%% VOICEOVER ON
% Raw data is seldom perfect. Missing values, inconsistent formats, and outliers are the norm. Manual cleaning is slow and error-prone.
%
% Instead, we want automated preprocessing pipelines:
% - Define clear rules for handling missing data, outliers, or strange values.
% - Ensure reproducibility: the same input dataset always leads to the same cleaned output.
% - Improve transparency: well-documented preprocessing code reduces guesswork and bias.
%
% This automation lays a solid foundation for fair and accurate modeling later on.
%%% VOICEOVER OFF
\begin{frame}{Automated Data Preprocessing}
\begin{itemize}
\item Systematically detect and address missing or inconsistent values
\item Standardize units, formats, and encodings without manual intervention
\item Increase reproducibility, reduce human bias and manual errors
\end{itemize}

\emph{Automation lets us spend less time fixing data manually, and more time ensuring quality and fairness.}
\end{frame}

%------------------------------------------------------------
% Techniques for Data Cleaning and Transformation
%------------------------------------------------------------
%%% VOICEOVER ON
% Let’s get practical. Suppose we have a dataset with missing values, mixed data formats, and categorical variables that need encoding. How do we automate this?
%
% - Missing Values: Use Python’s `pandas` to detect nulls and `scikit-learn`’s imputation methods.
% - Outliers: Identify with statistical rules (e.g., IQR-based filters) and handle them programmatically.
% - Feature transformations: Standardizing numeric features, encoding categorical features, or normalizing text.
%
% Let’s see a brief code snippet. We’ll assume we’re dealing with a `pandas` DataFrame and using `scikit-learn` transformers.
%%% VOICEOVER OFF
\begin{frame}{Practical Preprocessing Techniques}
\begin{minted}[fontsize=\small]{python}
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Load your raw data
df = pd.read_csv("raw_data.csv")

# Handle missing numeric values by imputing the mean
numeric_cols = df.select_dtypes(include=['float', 'int']).columns
imputer = SimpleImputer(strategy='mean')
df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

# One-hot encode categorical variables
categorical_cols = df.select_dtypes(include=['object']).columns
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
encoded = encoder.fit_transform(df[categorical_cols])
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))
df = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)

# Scale numeric features for model readiness
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
\end{minted}

\vspace{0.8em}
\emph{This code systematically cleans, encodes, and scales your data, making preprocessing repeatable and transparent.}
\end{frame}

%------------------------------------------------------------
% Data Validation and Quality Assurance
%------------------------------------------------------------
%%% VOICEOVER ON
% Cleaning is step one. Next is validation: ensuring that the cleaned data meets certain quality standards:
% - Schema checks: Are all expected columns present?
% - Range checks: Do values fall within expected boundaries?
% - Distribution checks: Have key statistics drifted compared to a known baseline?
%
% We can automate these checks at the start of our pipeline. If something’s off, we log it and halt downstream processes.
%
% Let’s look at an example of automated validation checks using Python’s `pandera` library, which lets you define data schemas and validate DataFrames.
%%% VOICEOVER OFF
\begin{frame}{Data Quality Assurance}
\begin{minted}[fontsize=\small]{python}
import pandera as pa
from pandera.typing import DataFrame, Series

# Define a schema
class InputSchema(pa.SchemaModel):
    age: Series[int] = pa.Field(ge=0, le=120)
    income: Series[float] = pa.Field(ge=0)
    # Add more columns and constraints as needed

    class Config:
        strict = True  # no unexpected columns allowed

# Validate the dataframe
try:
    validated_df = InputSchema.validate(df)
except pa.errors.SchemaError as e:
    # Log error and halt the pipeline
    print("Data validation failed:", e)
    # handle the error (e.g., send alert, stop the pipeline)
\end{minted}

\vspace{0.8em}
\emph{In practice, this ensures we catch data issues before model training, improving reliability and trust.}
\end{frame}

%------------------------------------------------------------
% Ethical Data Management: Privacy & Regulations
%------------------------------------------------------------
%%% VOICEOVER ON
% Ethical handling also means respecting privacy and obeying laws like GDPR.
%
% Strategies:
% - Pseudonymization: Replace direct identifiers (names, SSNs) with anonymized keys.
% - Encryption at rest and in transit.
% - Minimize data: Store only what’s necessary for modeling.
% - Allow opt-outs and honor “right to be forgotten” requests.
%
% In code, this might mean hashing IDs or removing identifiable columns before storage. Let’s see a snippet.
%%% VOICEOVER OFF
\begin{frame}{Privacy Protection and Compliance}
\begin{minted}[fontsize=\small]{python}
import hashlib

# Example: Pseudonymize user IDs
if 'user_id' in df.columns:
    df['user_id_hashed'] = df['user_id'].apply(
        lambda x: hashlib.sha256(str(x).encode()).hexdigest()
    )
    df.drop(columns=['user_id'], inplace=True)

# Remove personally identifiable information (PII)
pii_columns = ['name', 'email', 'phone_number']
df = df.drop(columns=[col for col in pii_columns if col in df.columns])

# Further steps could include encryption for storage or implementing user consent checks
\end{minted}

\vspace{0.8em}
\emph{Integrating privacy measures at the data layer reduces risks and builds user trust.}
\end{frame}

%------------------------------------------------------------
% Ethical Data Management: Bias Detection
%------------------------------------------------------------
%%% VOICEOVER ON
% Even if data is clean and private, it can still encode societal biases. We must inspect distributions and outcomes across groups (e.g., gender, ethnicity) to detect unfair patterns.
%
% Tools like `aif360` (by IBM) provide fairness metrics and methods to adjust datasets. For example, we can measure disparate impact or demographic parity and then re-balance the training set if needed.
%
% Let’s see a code snippet using `aif360` to detect and mitigate bias. Assume we have a dataset with a sensitive attribute like “gender.”
%%% VOICEOVER OFF
\begin{frame}{Detecting and Mitigating Bias}
\begin{minted}[fontsize=\small]{python}
from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric
from aif360.algorithms.preprocessing import Reweighing

# Convert df to aif360 dataset, specifying label and protected attribute
data = BinaryLabelDataset(
    favorable_label=1,
    unfavorable_label=0,
    df=df,
    label_names=['approved_loan'],
    protected_attribute_names=['gender']
)

metric = BinaryLabelDatasetMetric(data, unprivileged_groups=[{'gender':0}],
                                  privileged_groups=[{'gender':1}])

# Check disparate impact (ratio of favorable outcomes between groups)
disparate_impact = metric.disparate_impact()
print("Disparate Impact:", disparate_impact)

# If disparate impact < 0.8, consider reweighing
if disparate_impact < 0.8:
    rw = Reweighing(unprivileged_groups=[{'gender':0}],
                    privileged_groups=[{'gender':1}])
    data_transformed = rw.fit_transform(data)
    # data_transformed can now be used for modeling with less bias
\end{minted}

\vspace{0.8em}
\emph{By detecting and adjusting for bias pre-training, we ensure models are more equitable.}
\end{frame}

%------------------------------------------------------------
% Putting It All Together
%------------------------------------------------------------
%%% VOICEOVER ON
% We’ve seen:
% - Why ethics matters: It preserves trust and prevents harm.
% - How to automate data cleaning with code: Ensuring reproducibility and transparency.
% - How to validate data quality: Early checks to catch problems.
% - How to enforce privacy and comply with regulations like GDPR: Minimizing and securing data.
% - How to detect and mitigate bias: Using fairness metrics and preprocessing techniques.
%
% Combined, these measures produce a data pipeline that is robust, private, and equitable. By incorporating these techniques into our daily workflows, we don’t just talk about ethics—we practice it.
%%% VOICEOVER OFF
\begin{frame}{A Holistic Data Strategy}
\begin{itemize}
\item Integrate cleaning, validation, privacy, and bias mitigation into one automated flow
\item Document steps for transparency and auditability
\item Regularly iterate and improve based on feedback and monitoring
\end{itemize}

\emph{A well-structured, ethical data pipeline is the backbone of fair and effective AI systems.}
\end{frame}

%------------------------------------------------------------
% Conclusion & Next Steps
%------------------------------------------------------------
%%% VOICEOVER ON
% We’ve set the stage for ethical modeling by ensuring the data feeding our models is trustworthy, private, and fair.
%
% In our next presentation, we’ll dive into automated model training and evaluation pipelines. We’ll see how our ethically prepared data empowers fairer and more reliable model outcomes. We’ll also learn about model versioning, continuous integration, and continuous delivery to ensure that these ethical practices persist as our systems evolve.
%
% This journey—from raw data to responsibly trained models—is a continuous cycle. By making ethical and automated data handling our standard practice, we ensure that every subsequent step in the ML lifecycle is built on rock-solid foundations.
%%% VOICEOVER OFF
\begin{frame}{Next Steps}
\begin{itemize}
\item Next Presentation: Automated Model Training \& Ethical Evaluation
\item Connect ethical data pipelines to model building and deployment best practices
\end{itemize}

\emph{The path ahead: turning ethical principles into sustainable, real-world AI solutions.}
\end{frame}

\end{document}
