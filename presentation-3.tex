\documentclass[aspectratio=169]{beamer}

% Modern theme & fonts with T1 encoding
\usetheme{metropolis}
\usefonttheme{professionalfonts}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{bookmark}

% Metropolis adjustments
\metroset{progressbar=none}
\setbeamertemplate{footline}{}

% Colors and frame title formatting
\setbeamercolor{normal text}{fg=black,bg=white}
\setbeamercolor{background canvas}{bg=white}
\setbeamercolor{frametitle}{fg=black,bg=white}

% Center frame titles
\makeatletter
\setbeamertemplate{frametitle}{
  \nointerlineskip%
  \begin{beamercolorbox}[wd=\paperwidth, sep=0.3cm, center]{frametitle}%
    \usebeamerfont{frametitle}\insertframetitle\par%
    \if\insertframesubtitle\relax%
    \else%
      \vspace{0.5em}%
      {\usebeamerfont{framesubtitle}\insertframesubtitle\par}%
    \fi%
  \end{beamercolorbox}%
}
\makeatother

% Packages
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    bookmarksnumbered=true
}
\usepackage{etoolbox}
\usepackage{media9}
\usepackage{minted}
\usemintedstyle{friendly}
\usepackage{menukeys}

\title{Data Preparation \& Ethical Data Handling}
\subtitle{AI Masters Capstone Project - Presentation 2}
\author{Jonathan Agustin}
\date{November 2024}

\begin{document}

%------------------------------------------------------------
% Title Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Welcome to our deep dive into building not just ethical and automated ML pipelines, but truly expert-level data workflows.
% Last time, we established the importance of automation and ethics in ML. Today, we’ll elevate these concepts further:
% - We’ll reveal “power moves” in data cleaning, from advanced transformations to reproducible and transparent workflows.
% - We’ll discuss how to incorporate privacy and fairness from day one, avoiding common pitfalls that often surface only after a product launches.
% - We’ll also revisit the art and science of building validation sets, referencing Rachel Thomas (2017), but now focusing on the subtle, high-leverage strategies the top ML practitioners rely on.
% Let’s dive in and ensure our data handling not only meets standards but sets new ones.
%%% VOICEOVER OFF
\maketitle

%------------------------------------------------------------
% Overview Slide
%------------------------------------------------------------
%%% VOICEOVER ON
% Today’s agenda focuses on advanced strategies and hidden gems of data preparation:
% 1. Going beyond basics: embedding ethical principles deep into data pipelines.
% 2. Expert-level preprocessing: pipeline reproducibility, monitoring, and clever feature engineering.
% 3. Data validation “power tools” that catch subtle errors before they cascade downstream.
% 4. Privacy & compliance tips that surpass mere box-checking—learn how to future-proof for evolving regulations.
% 5. Building a validation set inspired by Thomas (2017), but with added sophistication: incorporating domain insights, multiple validation splits, and controlled scenario testing.
% 6. Cutting-edge bias detection and mitigation techniques that adapt as your data and models evolve.
%
% By the end, you’ll have a toolbox of “insider” moves to ensure your entire ML pipeline is robust, fair, and aligned with real-world conditions.
%%% VOICEOVER OFF
\begin{frame}{What We’ll Cover Today}
\begin{itemize}
\item Embedding ethics and fairness at the pipeline level
\item Advanced automated preprocessing: beyond missing values
\item Rigorous data validation: schema enforcement + anomaly detection
\item Future-proofed privacy \& compliance (e.g., GDPR and beyond)
\item Expert validation set design (Thomas, 2017) for real-world resilience
\item Next-level bias detection and rebalancing strategies
\end{itemize}

\vspace{0.8em}
\emph{We’re moving from “good enough” to elite data practices that anticipate tomorrow’s challenges.}
\end{frame}

%------------------------------------------------------------
% Importance of Ethical Data Handling
%------------------------------------------------------------
%%% VOICEOVER ON
% Ethical data handling is not just compliance—it's your competitive advantage. Leading ML teams know that public trust is hard to earn and easy to lose.
% By weaving ethics into every data decision, you elevate quality, reputation, and user confidence.
% Expert tip: Proactively consult domain experts (legal, social sciences, policy) early. Preempt legal headaches and PR crises by getting it right the first time.
%%% VOICEOVER OFF
\begin{frame}{Ethical Data Handling Matters}
\begin{itemize}
\item Data isn’t just numbers—it’s people’s lives and societal narratives.
\item Anticipate downstream impacts: prevent models that discriminate or misinform.
\item Build trust: ethical data stewardship differentiates you in a crowded market.
\item **Pro tip:** Involve domain and ethics experts from project inception, not as an afterthought.
\end{itemize}

\emph{Ethics done expertly: a strategic investment, not a cost.}
\end{frame}

%------------------------------------------------------------
% Automated Data Preprocessing: Advanced Insights
%------------------------------------------------------------
%%% VOICEOVER ON
% Moving beyond basic cleaning:
% - Standardization is table stakes. Top teams integrate advanced transformations, like domain-aware feature scaling, automated feature selection, and dynamic pipeline scripts that adapt to new data.
% - Store all preprocessing parameters in version control for full reproducibility. Consider using tools like DVC, MLflow, or Great Expectations for monitoring data quality over time.
% - Embrace modular pipelines: break down cleaning steps into reusable, documented components.
%%% VOICEOVER OFF
\begin{frame}{Automated Preprocessing “Power Moves”}
\begin{itemize}
\item Dynamic and modular pipelines: easy to update when data schema evolves
\item Parametrized transformations: track imputation strategies, encoders, scalers in version control
\item CI/CD integration: automated checks prevent subtle data drifts from reaching production
\item Advanced transformations: leverage domain knowledge to engineer more predictive features from raw inputs
\end{itemize}

\emph{Set up your pipeline so that improvements flow seamlessly, without reinventing the wheel.}
\end{frame}

%------------------------------------------------------------
% Techniques for Data Cleaning and Transformation (Enhanced)
%------------------------------------------------------------
%%% VOICEOVER ON
% Consider a scenario: you not only impute missing values but also log data drift, document changes, and automatically retrain imputers as distributions shift.
% Introduce advanced encodings (like target encodings) and combine them with strict validation rules. By doing so, you maintain a self-correcting pipeline that grows smarter over time.
%%% VOICEOVER OFF
\begin{frame}{Practical Preprocessing Techniques (Expert-Level)}
\begin{minted}[fontsize=\small]{python}
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
# Consider advanced encoders from category_encoders
from category_encoders import TargetEncoder
import mlflow

df = pd.read_csv("raw_data.csv")

# Log data schema version
mlflow.set_experiment("data_preprocessing")
with mlflow.start_run():
    mlflow.log_param("raw_data_shape", df.shape)

numeric_cols = df.select_dtypes(include=['float','int']).columns
imputer = SimpleImputer(strategy='median')
df[numeric_cols] = imputer.fit_transform(df[numeric_cols])

categorical_cols = df.select_dtypes(include=['object']).columns
# Advanced encoding: TargetEncoder for high-cardinality features
encoder = TargetEncoder(cols=categorical_cols)
df[categorical_cols] = encoder.fit_transform(df[categorical_cols], df['target_variable'])

scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

mlflow.log_metric("post_imputation_missing", df.isnull().sum().sum())
mlflow.end_run()
\end{minted}

\emph{By logging parameters and metrics, you track performance and data shifts over time—like pros do.}
\end{frame}

%------------------------------------------------------------
% Data Validation and Quality Assurance (Advanced)
%------------------------------------------------------------
%%% VOICEOVER ON
% Beyond checking schemas, expert practitioners run anomaly detection (e.g., isolation forests), statistical sanity checks, and rules that adapt as the business logic evolves.
% Use tools like Great Expectations or pandera with CI/CD so that any unexpected data gets flagged before it hits production models.
% Consider multiple validation tiers: from schema checks to domain-driven outlier detection.
%%% VOICEOVER OFF
\begin{frame}{Data Quality Assurance: Advanced Strategies}
\begin{minted}[fontsize=\small]{python}
import pandera as pa
from pandera.typing import DataFrame, Series
from pandera import Check

class InputSchema(pa.SchemaModel):
    age: Series[int] = pa.Field(ge=0, le=120)
    income: Series[float] = pa.Field(ge=0)
    # Add dynamic checks that reference domain insights
    target_variable: Series[int] = pa.Field(in_values=[0,1])

    class Config:
        strict = True

# Add anomaly checks for advanced validation
schema = InputSchema.to_schema().add_checks(
    Check(lambda df: df['income'].mean() < 1e6,
          error="Average income suspiciously high")
)

try:
    validated_df = schema.validate(df)
except pa.errors.SchemaError as e:
    print("Data validation failed:", e)
    # Integrate with alerting systems (PagerDuty, Slack)
\end{minted}

\emph{Expert-level validation: layered checks, domain logic, automated alerts.}
\end{frame}

%------------------------------------------------------------
% Creating a Good Validation Set (Thomas, 2017) - Expert Take
%------------------------------------------------------------
%%% VOICEOVER ON
% Rachel Thomas (2017) offers the core principle: validation sets must reflect future conditions.
% Expert approach:
% - Use multiple validation sets, each simulating a different future scenario (time-based splits, new user segments, unexpected domain shifts).
% - Continuously reassess the validation scheme as the product context evolves.
% - Integrate domain expertise: if future data may come from a new geography, include it in validation scenarios even before the data fully arrives.
%%% VOICEOVER OFF
\begin{frame}{Crafting Expert-Level Validation Sets (Thomas, 2017)}
\begin{itemize}
\item Multiple “scenario-based” validation sets, not just one
\item Time-based splits that reflect production roll-out schedules
\item Varying user cohorts to mimic new demographics or products
\item Regularly refresh validation sets as data distribution drifts
\end{itemize}

\emph{Top teams treat validation sets as living assets—continuously improved for maximum realism.}
\end{frame}

%------------------------------------------------------------
% When Random Subsets Are Not Enough: Advanced Scenarios
%------------------------------------------------------------
%%% VOICEOVER ON
% Go beyond just time-based or new-entity splits:
% - Integrate stress tests: artificially remove certain feature distributions to see if the model can handle unpredictable future changes.
% - Perform “jackknife” validations where you systematically leave out certain cohorts to test model robustness.
% - Monitor performance not just overall, but per-segment, ensuring fairness across all user groups.
%%% VOICEOVER OFF
\begin{frame}{Beyond Random Splits: Pro-Level Validation (Thomas, 2017)}
\begin{itemize}
\item **Stress Testing**: Remove entire feature segments to simulate sensor failures or data pipeline downtime.
\item **Cohort-Based Validation**: Validate on subsets representing future strategic markets or demographics.
\item **Multi-Stage Validation**: Incrementally reveal validation data, mirroring real-time production data arrival.
\end{itemize}

\emph{Such techniques yield resilience and maintain trust as conditions evolve.}
\end{frame}

%------------------------------------------------------------
% Practical Examples: Enhanced Realism
%------------------------------------------------------------
%%% VOICEOVER ON
% Example:
% - For a time series forecasting model, build multiple validation windows rolling forward in monthly increments. Compare stability over time.
% - For a recommender system expecting new product lines, create a validation set that excludes these items from training entirely, ensuring the model can adapt.
% - Periodically swap out validation sets to reflect seasonal changes.
%%% VOICEOVER OFF
\begin{frame}{Practical Expert-Level Examples (Thomas, 2017)}
\begin{itemize}
\item **Time Series**: Rolling window validations (e.g., train on Jan–May, validate on June; then train on Feb–June, validate on July, etc.)
\item **New Entities**: Introduce synthetic "unseen" products or users to test model adaptability.
\item **Domain Shifts**: Create scenario-based validations if you anticipate policy changes, new competitor products, or economic downturns.
\end{itemize}

\emph{Master-level validation ensures future-readiness and stable performance in a dynamic world.}
\end{frame}

%------------------------------------------------------------
% Avoiding Overfitting to Public Benchmarks (Kaggle & Beyond)
%------------------------------------------------------------
%%% VOICEOVER ON
% As Thomas (2017) notes, relying solely on a platform’s public leaderboard can lead to subtle overfitting.
% Expert tips:
% - Maintain your own robust validation suites that simulate multiple futures.
% - Don’t chase incremental leaderboard gains that vanish in production. Use domain knowledge and scenario tests to keep the model honest.
% - Track long-term performance stability instead of one-off leaderboard spikes.
%%% VOICEOVER OFF
\begin{frame}{Kaggle & Production: Insider Secrets (Thomas, 2017)}
\begin{itemize}
\item Maintain independent validation sets that align with long-term product goals.
\item Don’t let public leaderboard scores dictate final decisions—correlate with private validation sets.
\item Regularly “audit” model performance over multiple, evolving validation sets for stable generalization.
\end{itemize}

\emph{This is how you avoid “trophy overfitting” and achieve genuine real-world impact.}
\end{frame}

%------------------------------------------------------------
% Ethical Data Management: Privacy & Compliance - Pro-Level
%------------------------------------------------------------
%%% VOICEOVER ON
% Privacy isn’t static. Today’s GDPR might be tomorrow’s stricter regulation.
% Expert moves:
% - Build anonymization and compliance checks into the pipeline. Keep them configurable, so you can rapidly adapt to new laws.
% - Explore differential privacy techniques for sensitive datasets.
% - Leverage automated auditing: schedule periodic privacy assessments and vulnerability scans.
%%% VOICEOVER OFF
\begin{frame}{Privacy Protection: Future-Proof & Flexible}
\begin{minted}[fontsize=\small]{python}
import hashlib
# Hash sensitive IDs
if 'user_id' in df.columns:
    df['user_id_hashed'] = df['user_id'].apply(
        lambda x: hashlib.sha256(str(x).encode()).hexdigest()
    )
    df.drop(columns=['user_id'], inplace=True)

# Drop direct PII and consider synthetic data generation if needed
pii_cols = ['name','email','phone_number']
df = df.drop(columns=[c for c in pii_cols if c in df.columns])

# Expert tip: integrate a differential privacy library
# to add statistical noise to sensitive aggregates.
# e.g., "privacy_engine" from Opacus (for PyTorch)
\end{minted}

\emph{By designing flexible compliance tools, you stay ahead of evolving regulatory landscapes.}
\end{frame}

%------------------------------------------------------------
% Detecting and Mitigating Bias: Cutting-Edge Techniques
%------------------------------------------------------------
%%% VOICEOVER ON
% Beyond basic bias checks:
% - Continuously monitor bias metrics over time—bias can emerge as data shifts.
% - Explore advanced reweighting or adversarial debiasing methods.
% - Test bias across multiple intersectional groups, not just one protected attribute.
% - Implement bias dashboards that alert when performance disparities worsen.
%%% VOICEOVER OFF
\begin{frame}{Bias Detection and Mitigation: Advanced Methods}
\begin{minted}[fontsize=\small]{python}
from aif360.datasets import BinaryLabelDataset
from aif360.algorithms.inprocessing import AdversarialDebiasing
from aif360.metrics import ClassificationMetric

data = BinaryLabelDataset(
    favorable_label=1,
    unfavorable_label=0,
    df=df,
    label_names=['approved_loan'],
    protected_attribute_names=['gender']
)

# Check intersectional groups if available
# Use adversarial debiasing to reduce discrimination
debiasing_model = AdversarialDebiasing(
    unprivileged_groups=[{'gender':0}],
    privileged_groups=[{'gender':1}],
    scope_name='debiasing_model',
    sess=None
)
# Fit this model and evaluate metrics like equalized odds over time
\end{minted}

\emph{Top practitioners treat bias mitigation as an ongoing process, not a one-time fix.}
\end{frame}

%------------------------------------------------------------
% Putting It All Together
%------------------------------------------------------------
%%% VOICEOVER ON
% You now have a blueprint for expert-level data handling:
% - Ethical principles woven throughout the pipeline.
% - Advanced preprocessing and validation strategies that embrace complexity and change.
% - Tailored validation sets that genuinely prepare you for the unknown.
% - Robust privacy controls and next-gen bias mitigation techniques.
%
% This integrated approach ensures your models perform reliably and fairly, even under shifting real-world conditions.
%%% VOICEOVER OFF
\begin{frame}{A Holistic, Expert Data Strategy}
\begin{itemize}
\item Pipeline as a living system: continuously evolving and improving
\item Ethical, privacy-first approach as a strategic differentiator
\item Validation sets as flexible testbeds for future conditions
\item Bias mitigation as a dynamic, iterative practice
\end{itemize}

\emph{These tactics don’t just solve problems—they preempt them, ensuring your ML solutions stand the test of time.}
\end{frame}

%------------------------------------------------------------
% Conclusion & Next Steps
%------------------------------------------------------------
%%% VOICEOVER ON
% With these expert-level strategies in place, your data is primed for ethical, robust modeling.
% In the next session, we’ll dive deeper into automated model training and evaluation, carrying forward the principles of fairness, transparency, and resilience you’ve established in your data pipeline.
%%% VOICEOVER OFF
\begin{frame}{Next Steps}
\begin{itemize}
\item Next: Automating Model Training \& Ethical Model Evaluation
\item Connect these expert data strategies to model tuning and monitoring
\end{itemize}

\emph{You’re now ready to build ML pipelines that aren’t just good—they’re world-class.}
\end{frame}

%------------------------------------------------------------
% References
%------------------------------------------------------------
\begin{frame}{References}
\footnotesize
\begin{itemize}
\item Thomas, R. (2017). \textit{How (and why) to create a good validation set}. Retrieved from \url{https://rachel.fast.ai/posts/2017-11-13-validation-sets/}
\item \textit{AIF360} toolkit: \url{https://github.com/Trusted-AI/AIF360}
\item \textit{pandera} library: \url{https://pandera.readthedocs.io/}
\item GDPR guidelines: \url{https://gdpr.eu/}
\item Opacus (differential privacy for PyTorch): \url{https://github.com/pytorch/opacus}
\item Great Expectations (data quality): \url{https://greatexpectations.io/}
\end{itemize}
\end{frame}

\end{document}
