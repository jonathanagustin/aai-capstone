\frametitle{Detecting and Mitigating Bias}
\begin{minted}[fontsize=\small]{python}
from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric
from aif360.algorithms.preprocessing import Reweighing

data = BinaryLabelDataset(
    favorable_label=1,
    unfavorable_label=0,
    df=df,
    label_names=['approved_loan'],
    protected_attribute_names=['gender']
)

metric = BinaryLabelDatasetMetric(
    data,
    unprivileged_groups=[{'gender':0}],
    privileged_groups=[{'gender':1}]
)

if metric.disparate_impact() < 0.8:
    rw = Reweighing(
        unprivileged_groups=[{'gender':0}],
        privileged_groups=[{'gender':1}]
    )
    data_balanced = rw.fit_transform(data)
\end{minted}

\emph{Embedding fairness checks ensures our ML solutions serve society responsibly.}
